{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.28809009362928045,
  "eval_steps": 500,
  "global_step": 4400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032737510639690957,
      "grad_norm": 1.7895636558532715,
      "learning_rate": 9.993583447914621e-05,
      "loss": 3.131,
      "step": 50
    },
    {
      "epoch": 0.0065475021279381915,
      "grad_norm": 1.3566447496414185,
      "learning_rate": 9.987035945786682e-05,
      "loss": 1.4358,
      "step": 100
    },
    {
      "epoch": 0.009821253191907287,
      "grad_norm": 0.5038736462593079,
      "learning_rate": 9.980488443658744e-05,
      "loss": 1.1051,
      "step": 150
    },
    {
      "epoch": 0.013095004255876383,
      "grad_norm": 0.6033567190170288,
      "learning_rate": 9.973940941530805e-05,
      "loss": 1.0749,
      "step": 200
    },
    {
      "epoch": 0.01636875531984548,
      "grad_norm": 0.811981201171875,
      "learning_rate": 9.967393439402868e-05,
      "loss": 0.9966,
      "step": 250
    },
    {
      "epoch": 0.019642506383814574,
      "grad_norm": 1.7097642421722412,
      "learning_rate": 9.96084593727493e-05,
      "loss": 1.0397,
      "step": 300
    },
    {
      "epoch": 0.02291625744778367,
      "grad_norm": 0.6372198462486267,
      "learning_rate": 9.954298435146991e-05,
      "loss": 1.0158,
      "step": 350
    },
    {
      "epoch": 0.026190008511752766,
      "grad_norm": 0.8485772609710693,
      "learning_rate": 9.947750933019053e-05,
      "loss": 1.03,
      "step": 400
    },
    {
      "epoch": 0.02946375957572186,
      "grad_norm": 0.6674455404281616,
      "learning_rate": 9.941203430891116e-05,
      "loss": 0.9764,
      "step": 450
    },
    {
      "epoch": 0.03273751063969096,
      "grad_norm": 0.7499642372131348,
      "learning_rate": 9.934655928763177e-05,
      "loss": 1.0099,
      "step": 500
    },
    {
      "epoch": 0.03601126170366006,
      "grad_norm": 0.463326632976532,
      "learning_rate": 9.928108426635239e-05,
      "loss": 1.0285,
      "step": 550
    },
    {
      "epoch": 0.03928501276762915,
      "grad_norm": 0.4473186731338501,
      "learning_rate": 9.9215609245073e-05,
      "loss": 0.945,
      "step": 600
    },
    {
      "epoch": 0.04255876383159825,
      "grad_norm": 1.296296238899231,
      "learning_rate": 9.915013422379362e-05,
      "loss": 0.931,
      "step": 650
    },
    {
      "epoch": 0.04583251489556734,
      "grad_norm": 1.1889526844024658,
      "learning_rate": 9.908465920251425e-05,
      "loss": 1.0274,
      "step": 700
    },
    {
      "epoch": 0.04910626595953644,
      "grad_norm": 0.9870983958244324,
      "learning_rate": 9.901918418123486e-05,
      "loss": 0.9601,
      "step": 750
    },
    {
      "epoch": 0.05238001702350553,
      "grad_norm": 0.7305631637573242,
      "learning_rate": 9.895370915995548e-05,
      "loss": 0.9743,
      "step": 800
    },
    {
      "epoch": 0.05565376808747463,
      "grad_norm": 1.1113773584365845,
      "learning_rate": 9.888823413867609e-05,
      "loss": 0.9473,
      "step": 850
    },
    {
      "epoch": 0.05892751915144372,
      "grad_norm": 0.7918972969055176,
      "learning_rate": 9.88227591173967e-05,
      "loss": 0.958,
      "step": 900
    },
    {
      "epoch": 0.06220127021541282,
      "grad_norm": 0.4384799003601074,
      "learning_rate": 9.875728409611733e-05,
      "loss": 0.9824,
      "step": 950
    },
    {
      "epoch": 0.06547502127938191,
      "grad_norm": 0.492890328168869,
      "learning_rate": 9.869180907483795e-05,
      "loss": 1.016,
      "step": 1000
    },
    {
      "epoch": 0.06874877234335101,
      "grad_norm": 0.7898808717727661,
      "learning_rate": 9.862633405355857e-05,
      "loss": 0.9436,
      "step": 1050
    },
    {
      "epoch": 0.07202252340732011,
      "grad_norm": 0.7571173310279846,
      "learning_rate": 9.856085903227918e-05,
      "loss": 0.8994,
      "step": 1100
    },
    {
      "epoch": 0.0752962744712892,
      "grad_norm": 1.6236497163772583,
      "learning_rate": 9.849538401099981e-05,
      "loss": 1.0212,
      "step": 1150
    },
    {
      "epoch": 0.0785700255352583,
      "grad_norm": 0.7225979566574097,
      "learning_rate": 9.842990898972044e-05,
      "loss": 0.9413,
      "step": 1200
    },
    {
      "epoch": 0.0818437765992274,
      "grad_norm": 0.6555227637290955,
      "learning_rate": 9.836443396844105e-05,
      "loss": 0.9084,
      "step": 1250
    },
    {
      "epoch": 0.0851175276631965,
      "grad_norm": 0.5047958493232727,
      "learning_rate": 9.829895894716167e-05,
      "loss": 0.9164,
      "step": 1300
    },
    {
      "epoch": 0.08839127872716558,
      "grad_norm": 0.5667930245399475,
      "learning_rate": 9.823348392588228e-05,
      "loss": 0.9944,
      "step": 1350
    },
    {
      "epoch": 0.09166502979113468,
      "grad_norm": 0.8993062376976013,
      "learning_rate": 9.81680089046029e-05,
      "loss": 1.0194,
      "step": 1400
    },
    {
      "epoch": 0.09493878085510378,
      "grad_norm": 0.40222224593162537,
      "learning_rate": 9.810253388332353e-05,
      "loss": 0.9401,
      "step": 1450
    },
    {
      "epoch": 0.09821253191907288,
      "grad_norm": 0.7943068146705627,
      "learning_rate": 9.803705886204414e-05,
      "loss": 0.919,
      "step": 1500
    },
    {
      "epoch": 0.10148628298304196,
      "grad_norm": 1.7591681480407715,
      "learning_rate": 9.797158384076476e-05,
      "loss": 0.9214,
      "step": 1550
    },
    {
      "epoch": 0.10476003404701106,
      "grad_norm": 1.075622320175171,
      "learning_rate": 9.790610881948537e-05,
      "loss": 0.9559,
      "step": 1600
    },
    {
      "epoch": 0.10803378511098016,
      "grad_norm": 0.48200446367263794,
      "learning_rate": 9.7840633798206e-05,
      "loss": 0.9248,
      "step": 1650
    },
    {
      "epoch": 0.11130753617494926,
      "grad_norm": 1.0135482549667358,
      "learning_rate": 9.777515877692662e-05,
      "loss": 0.9573,
      "step": 1700
    },
    {
      "epoch": 0.11458128723891835,
      "grad_norm": 1.1001341342926025,
      "learning_rate": 9.770968375564723e-05,
      "loss": 0.9028,
      "step": 1750
    },
    {
      "epoch": 0.11785503830288745,
      "grad_norm": 0.5703371167182922,
      "learning_rate": 9.764420873436785e-05,
      "loss": 0.9573,
      "step": 1800
    },
    {
      "epoch": 0.12112878936685655,
      "grad_norm": 0.35670191049575806,
      "learning_rate": 9.757873371308846e-05,
      "loss": 0.9464,
      "step": 1850
    },
    {
      "epoch": 0.12440254043082564,
      "grad_norm": 0.34756529331207275,
      "learning_rate": 9.751325869180909e-05,
      "loss": 0.8923,
      "step": 1900
    },
    {
      "epoch": 0.12767629149479473,
      "grad_norm": 0.4006407856941223,
      "learning_rate": 9.74477836705297e-05,
      "loss": 0.9375,
      "step": 1950
    },
    {
      "epoch": 0.13095004255876383,
      "grad_norm": 0.43354710936546326,
      "learning_rate": 9.738230864925032e-05,
      "loss": 0.9674,
      "step": 2000
    },
    {
      "epoch": 0.13422379362273293,
      "grad_norm": 0.3980487585067749,
      "learning_rate": 9.731683362797094e-05,
      "loss": 0.912,
      "step": 2050
    },
    {
      "epoch": 0.13749754468670203,
      "grad_norm": 0.4647516906261444,
      "learning_rate": 9.725135860669155e-05,
      "loss": 0.9427,
      "step": 2100
    },
    {
      "epoch": 0.14077129575067113,
      "grad_norm": 1.328441858291626,
      "learning_rate": 9.718588358541218e-05,
      "loss": 0.9821,
      "step": 2150
    },
    {
      "epoch": 0.14404504681464023,
      "grad_norm": 0.4414634704589844,
      "learning_rate": 9.71204085641328e-05,
      "loss": 0.9303,
      "step": 2200
    },
    {
      "epoch": 0.1473187978786093,
      "grad_norm": 0.533023476600647,
      "learning_rate": 9.705493354285341e-05,
      "loss": 0.9219,
      "step": 2250
    },
    {
      "epoch": 0.1505925489425784,
      "grad_norm": 0.5705200433731079,
      "learning_rate": 9.698945852157402e-05,
      "loss": 0.9569,
      "step": 2300
    },
    {
      "epoch": 0.1538663000065475,
      "grad_norm": 1.0595264434814453,
      "learning_rate": 9.692398350029465e-05,
      "loss": 0.9117,
      "step": 2350
    },
    {
      "epoch": 0.1571400510705166,
      "grad_norm": 0.7382090091705322,
      "learning_rate": 9.685850847901527e-05,
      "loss": 0.9676,
      "step": 2400
    },
    {
      "epoch": 0.1604138021344857,
      "grad_norm": 0.3836546242237091,
      "learning_rate": 9.679303345773588e-05,
      "loss": 0.9089,
      "step": 2450
    },
    {
      "epoch": 0.1636875531984548,
      "grad_norm": 0.6188450455665588,
      "learning_rate": 9.67275584364565e-05,
      "loss": 0.9212,
      "step": 2500
    },
    {
      "epoch": 0.1669613042624239,
      "grad_norm": 0.7788134813308716,
      "learning_rate": 9.666208341517711e-05,
      "loss": 0.9312,
      "step": 2550
    },
    {
      "epoch": 0.170235055326393,
      "grad_norm": 0.7559465765953064,
      "learning_rate": 9.659660839389774e-05,
      "loss": 0.934,
      "step": 2600
    },
    {
      "epoch": 0.17350880639036206,
      "grad_norm": 0.44666188955307007,
      "learning_rate": 9.653113337261836e-05,
      "loss": 0.907,
      "step": 2650
    },
    {
      "epoch": 0.17678255745433116,
      "grad_norm": 0.4888673424720764,
      "learning_rate": 9.646565835133897e-05,
      "loss": 0.8663,
      "step": 2700
    },
    {
      "epoch": 0.18005630851830026,
      "grad_norm": 0.5481242537498474,
      "learning_rate": 9.640018333005959e-05,
      "loss": 0.8917,
      "step": 2750
    },
    {
      "epoch": 0.18333005958226936,
      "grad_norm": 0.8594080209732056,
      "learning_rate": 9.63347083087802e-05,
      "loss": 0.9073,
      "step": 2800
    },
    {
      "epoch": 0.18660381064623846,
      "grad_norm": 0.6458077430725098,
      "learning_rate": 9.626923328750083e-05,
      "loss": 0.8628,
      "step": 2850
    },
    {
      "epoch": 0.18987756171020756,
      "grad_norm": 1.163704752922058,
      "learning_rate": 9.620375826622145e-05,
      "loss": 0.9307,
      "step": 2900
    },
    {
      "epoch": 0.19315131277417666,
      "grad_norm": 0.34344062209129333,
      "learning_rate": 9.613828324494206e-05,
      "loss": 0.8651,
      "step": 2950
    },
    {
      "epoch": 0.19642506383814576,
      "grad_norm": 0.9316455721855164,
      "learning_rate": 9.607280822366268e-05,
      "loss": 0.8719,
      "step": 3000
    },
    {
      "epoch": 0.19969881490211483,
      "grad_norm": 1.4459187984466553,
      "learning_rate": 9.60073332023833e-05,
      "loss": 0.9108,
      "step": 3050
    },
    {
      "epoch": 0.20297256596608393,
      "grad_norm": 1.9296404123306274,
      "learning_rate": 9.594185818110392e-05,
      "loss": 0.9535,
      "step": 3100
    },
    {
      "epoch": 0.20624631703005303,
      "grad_norm": 0.4297010898590088,
      "learning_rate": 9.587638315982454e-05,
      "loss": 0.9585,
      "step": 3150
    },
    {
      "epoch": 0.20952006809402213,
      "grad_norm": 0.7288843989372253,
      "learning_rate": 9.581090813854515e-05,
      "loss": 0.9037,
      "step": 3200
    },
    {
      "epoch": 0.21279381915799123,
      "grad_norm": 0.46201401948928833,
      "learning_rate": 9.574543311726577e-05,
      "loss": 0.8718,
      "step": 3250
    },
    {
      "epoch": 0.21606757022196033,
      "grad_norm": 0.7170537114143372,
      "learning_rate": 9.56799580959864e-05,
      "loss": 0.8975,
      "step": 3300
    },
    {
      "epoch": 0.21934132128592942,
      "grad_norm": 0.4187364876270294,
      "learning_rate": 9.561448307470701e-05,
      "loss": 0.919,
      "step": 3350
    },
    {
      "epoch": 0.22261507234989852,
      "grad_norm": 0.9402081370353699,
      "learning_rate": 9.554900805342762e-05,
      "loss": 0.8936,
      "step": 3400
    },
    {
      "epoch": 0.22588882341386762,
      "grad_norm": 0.695681095123291,
      "learning_rate": 9.548353303214824e-05,
      "loss": 0.8673,
      "step": 3450
    },
    {
      "epoch": 0.2291625744778367,
      "grad_norm": 0.6448713541030884,
      "learning_rate": 9.541805801086885e-05,
      "loss": 0.8776,
      "step": 3500
    },
    {
      "epoch": 0.2324363255418058,
      "grad_norm": 0.6980531811714172,
      "learning_rate": 9.535258298958948e-05,
      "loss": 0.933,
      "step": 3550
    },
    {
      "epoch": 0.2357100766057749,
      "grad_norm": 0.7318702936172485,
      "learning_rate": 9.52871079683101e-05,
      "loss": 0.9246,
      "step": 3600
    },
    {
      "epoch": 0.238983827669744,
      "grad_norm": 0.3529755771160126,
      "learning_rate": 9.522163294703071e-05,
      "loss": 0.9259,
      "step": 3650
    },
    {
      "epoch": 0.2422575787337131,
      "grad_norm": 0.5429538488388062,
      "learning_rate": 9.515615792575133e-05,
      "loss": 0.9424,
      "step": 3700
    },
    {
      "epoch": 0.2455313297976822,
      "grad_norm": 1.8825197219848633,
      "learning_rate": 9.509068290447196e-05,
      "loss": 0.9745,
      "step": 3750
    },
    {
      "epoch": 0.2488050808616513,
      "grad_norm": 0.8794457912445068,
      "learning_rate": 9.502520788319257e-05,
      "loss": 0.9096,
      "step": 3800
    },
    {
      "epoch": 0.25207883192562036,
      "grad_norm": 0.7608832120895386,
      "learning_rate": 9.495973286191319e-05,
      "loss": 0.9152,
      "step": 3850
    },
    {
      "epoch": 0.25535258298958946,
      "grad_norm": 0.3831254243850708,
      "learning_rate": 9.48942578406338e-05,
      "loss": 0.9055,
      "step": 3900
    },
    {
      "epoch": 0.25862633405355856,
      "grad_norm": 0.3609519898891449,
      "learning_rate": 9.482878281935442e-05,
      "loss": 0.8204,
      "step": 3950
    },
    {
      "epoch": 0.26190008511752766,
      "grad_norm": 1.7257860898971558,
      "learning_rate": 9.476330779807505e-05,
      "loss": 0.8818,
      "step": 4000
    },
    {
      "epoch": 0.26517383618149676,
      "grad_norm": 0.5265693664550781,
      "learning_rate": 9.469783277679566e-05,
      "loss": 0.8937,
      "step": 4050
    },
    {
      "epoch": 0.26844758724546586,
      "grad_norm": 0.7746254801750183,
      "learning_rate": 9.463235775551628e-05,
      "loss": 0.9613,
      "step": 4100
    },
    {
      "epoch": 0.27172133830943496,
      "grad_norm": 0.47072651982307434,
      "learning_rate": 9.456688273423689e-05,
      "loss": 0.8851,
      "step": 4150
    },
    {
      "epoch": 0.27499508937340406,
      "grad_norm": 0.9887775778770447,
      "learning_rate": 9.450140771295751e-05,
      "loss": 0.9025,
      "step": 4200
    },
    {
      "epoch": 0.27826884043737315,
      "grad_norm": 0.7033935189247131,
      "learning_rate": 9.443593269167814e-05,
      "loss": 0.891,
      "step": 4250
    },
    {
      "epoch": 0.28154259150134225,
      "grad_norm": 1.370546817779541,
      "learning_rate": 9.437045767039875e-05,
      "loss": 0.898,
      "step": 4300
    },
    {
      "epoch": 0.28481634256531135,
      "grad_norm": 0.448948472738266,
      "learning_rate": 9.430498264911937e-05,
      "loss": 0.8806,
      "step": 4350
    },
    {
      "epoch": 0.28809009362928045,
      "grad_norm": 0.39702650904655457,
      "learning_rate": 9.423950762783998e-05,
      "loss": 0.8984,
      "step": 4400
    }
  ],
  "logging_steps": 50,
  "max_steps": 76365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2321294347468800.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
